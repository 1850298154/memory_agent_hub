# ARCMEMO: ABSTRACT REASONING COMPOSITION WITH LIFELONG LLM MEMORY


这篇文档讲的是一种给大语言模型（LLM）“装记忆”的新方法，名叫ArcMemo，目的是让模型在解决复杂推理问题时，能像人一样积累经验、复用之前的思路，不用每次都“从零开始”。

简单说，现在的大语言模型有个缺点：比如它解完一道复杂题后，过程中发现的规律、思路，只要上下文窗口一重置（比如开始解下一道题），这些东西就全忘了。之前也有给模型加“记忆”的尝试，但那些记忆大多是“死的”——比如直接存之前题目的完整答案或总结，只能用于和之前差不多的题，遇到表面不一样但核心思路相通的题，就用不上了。

而ArcMemo的核心就是做“活的记忆”：它不存具体题目的答案，而是从解题过程里提炼出“通用概念”。比如解像素网格题时，不存“这道题要给蓝色像素涂色”，而是提炼出“根据像素对齐情况调整颜色”“判断物体是否相邻”这类能套用到其他题的通用思路，而且会把这些思路拆成独立的小模块，方便后续重新组合使用。

为了实现这种“活记忆”，ArcMemo做了两件关键事：
一是“写记忆”：把解题过程提炼成通用概念。比如用两种方式整理记忆——一种是灵活的“开放式记录”（简单写清“什么场景下用什么思路”），另一种是更规整的“程序式记录”（像写代码一样，明确思路的类型、参数、适用条件，方便精准复用）。
二是“读记忆”：解新题时，不是把所有记忆都塞给模型，而是挑出最相关的。比如解像素题时，先用视觉模型把题目描述成文字，再匹配记忆里相关的通用思路；遇到难一点的题，还会让模型主动“思考”哪些思路能用上，而不是只靠简单的关键词匹配。

研究者用ARC-AGI这个 benchmark（主要考像素网格推理，需要灵活组合思路，很适合测记忆的复用能力）做了测试，结果还不错：用ArcMemo的模型，比没记忆的模型成绩提高了7.5%，而且随着计算资源增加（比如多试几次解题），成绩还能继续涨。另外，测试中发现，让模型在解题过程中不断更新记忆（比如解完10道题就补充新提炼的思路），比用固定不变的记忆效果更好，这也说明模型能通过积累记忆“自我提升”。

不过目前也有局限，比如只测了100道题（为了节省成本），没在更难的ARC-AGI-2上试；而且记忆的“挑选准确率”还有提升空间，偶尔会选到无关的思路。未来计划把测试范围扩大，还想研究怎么让记忆更有层次（比如把零散思路整理成体系），让模型的“经验积累”更高效。