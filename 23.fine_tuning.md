
**选择性微调策略Freeze**
- 定义：“Freeze”（冻结微调）指在微调时冻结绝大部分预训练模型层，只微调极少数关键参数（通常是最后的输出层或顶层几层）。也即，仅允许少部分参数参与训练，其余大部分参数的梯度更新被关闭。这样模型利用预训练时学到的大量通用特征，仅通过调整少量参数来适应新任务。
- 优点：冻结大部分参数使需训练的参数量大幅减少，显著节省计算资源和显存占用。对数据或算力有限的场景，Freeze策略非常适用，能在低资源环境下快速微调模型。同时，大部分参数被固定，预训练模型的已有知识和表示能力得以保留，有助于避免对小数据微调时的过拟合，保持模型稳定性和泛化能力。整体而言，Freeze方法简单易行，实现成本低，在确保一定性能的前提下极大降低了微调开销。
- DiffPruning、FishMask、FAR 则引入了参数重要性评估机制，自动选择重要参数微调；此外只有 FAR 方法在训练阶段对模型作了局部重构以优化内存和计算。


